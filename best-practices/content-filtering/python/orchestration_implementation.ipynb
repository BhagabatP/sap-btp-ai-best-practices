{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and environment keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestration Implementation\n",
    "We can unify the method to call any model from SAP GenAI Hub using the Orchestration Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ContentFilter.__init__() missing 1 required positional argument: 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     20\u001b[39m output_filter_llama = LlamaGuard38bFilter(hate=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# config = OrchestrationConfig(\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     template=Template(\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#         messages=[\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[38;5;66;03m#     output_filtering=OutputFiltering(filters=[output_filter, output_filter_llama])\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     36\u001b[39m config = OrchestrationConfig(\n\u001b[32m     37\u001b[39m     template=Template(\n\u001b[32m     38\u001b[39m         messages=[\n\u001b[32m     39\u001b[39m             SystemMessage(\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful AI assistant.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     40\u001b[39m             UserMessage(\u001b[33m\"\u001b[39m\u001b[33m{{\u001b[39m\u001b[33m?text}}\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     41\u001b[39m         ]\n\u001b[32m     42\u001b[39m     ),\n\u001b[32m     43\u001b[39m     llm=LLM(\n\u001b[32m     44\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m     ),\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     filtering=\u001b[43mContentFilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_filter_llama\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m )\n\u001b[32m     49\u001b[39m orchestration_service = OrchestrationService(config=config)\n\u001b[32m     51\u001b[39m result = orchestration_service.run()\n",
      "\u001b[31mTypeError\u001b[39m: ContentFilter.__init__() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.models.content_filtering import InputFiltering, OutputFiltering, ContentFilter\n",
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter, AzureThreshold\n",
    "from gen_ai_hub.orchestration.models.llama_guard_3_filter import LlamaGuard38bFilter\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "input_filter= AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                  violence=AzureThreshold.ALLOW_SAFE,\n",
    "                                  self_harm=AzureThreshold.ALLOW_SAFE,\n",
    "                                  sexual=AzureThreshold.ALLOW_SAFE)\n",
    "input_filter_llama = LlamaGuard38bFilter(hate=True)\n",
    "output_filter = AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                   violence=AzureThreshold.ALLOW_SAFE_LOW,\n",
    "                                   self_harm=AzureThreshold.ALLOW_SAFE_LOW_MEDIUM,\n",
    "                                   sexual=AzureThreshold.ALLOW_ALL)\n",
    "output_filter_llama = LlamaGuard38bFilter(hate=True)\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=Template(\n",
    "        messages=[\n",
    "            SystemMessage(\"You are a helpful AI assistant.\"),\n",
    "            UserMessage(\"{{?text}}\"),\n",
    "        ]\n",
    "    ),\n",
    "    llm=LLM(\n",
    "        name=\"gpt-4o\",\n",
    "    ),\n",
    "    input_filtering=InputFiltering(filters=[input_filter,input_filter_llama]),\n",
    "    output_filtering=OutputFiltering(filters=[output_filter, output_filter_llama])\n",
    ")\n",
    "\n",
    "\n",
    "orchestration_service = OrchestrationService(config=config)\n",
    "\n",
    "result = orchestration_service.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
