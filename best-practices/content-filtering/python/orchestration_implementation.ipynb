{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and environment keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestration Implementation\n",
    "We can unify the method to call any model from SAP GenAI Hub using the Orchestration Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OrchestrationConfig.__init__() got an unexpected keyword argument 'input_filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     15\u001b[39m output_filter = AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n\u001b[32m     16\u001b[39m                                    violence=AzureThreshold.ALLOW_SAFE_LOW,\n\u001b[32m     17\u001b[39m                                    self_harm=AzureThreshold.ALLOW_SAFE_LOW_MEDIUM,\n\u001b[32m     18\u001b[39m                                    sexual=AzureThreshold.ALLOW_ALL)\n\u001b[32m     19\u001b[39m output_filter_llama = LlamaGuard38bFilter(hate=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m config = \u001b[43mOrchestrationConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful AI assistant.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43mUserMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m{{\u001b[39;49m\u001b[33;43m?text}}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_filters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mInputFiltering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_filter_llama\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_filters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOutputFiltering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_filter_llama\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m orchestration_service = OrchestrationService(config=config)\n\u001b[32m     36\u001b[39m result = orchestration_service.run()\n",
      "\u001b[31mTypeError\u001b[39m: OrchestrationConfig.__init__() got an unexpected keyword argument 'input_filters'"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.models.content_filtering import InputFiltering, OutputFiltering\n",
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter, AzureThreshold\n",
    "from gen_ai_hub.orchestration.models.llama_guard_3_filter import LlamaGuard38bFilter\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.template import Template\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage,UserMessage\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "input_filter= AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                  violence=AzureThreshold.ALLOW_SAFE,\n",
    "                                  self_harm=AzureThreshold.ALLOW_SAFE,\n",
    "                                  sexual=AzureThreshold.ALLOW_SAFE)\n",
    "input_filter_llama = LlamaGuard38bFilter(hate=True)\n",
    "output_filter = AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                   violence=AzureThreshold.ALLOW_SAFE_LOW,\n",
    "                                   self_harm=AzureThreshold.ALLOW_SAFE_LOW_MEDIUM,\n",
    "                                   sexual=AzureThreshold.ALLOW_ALL)\n",
    "output_filter_llama = LlamaGuard38bFilter(hate=True)\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=Template(\n",
    "        messages=[\n",
    "            SystemMessage(\"You are a helpful AI assistant.\"),\n",
    "            UserMessage(\"{{?text}}\"),\n",
    "        ]\n",
    "    ),\n",
    "    llm=LLM(\n",
    "        name=\"gpt-4o\",\n",
    "    ),\n",
    "    input_filters=InputFiltering(filters=[input_filter,input_filter_llama]),\n",
    "    output_filters=OutputFiltering(filters=[output_filter, output_filter_llama])\n",
    ")\n",
    "orchestration_service = OrchestrationService(config=config)\n",
    "\n",
    "result = orchestration_service.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
